
# S3 Infrastructure Setup

The `01-create-s3-buckets.sh` script is responsible for provisioning and managing the Amazon S3 infrastructure used by the Chicago Crimes application. Its primary role is to ensure that the storage layer required by the application is created consistently, secured correctly, and maintained automatically over time. The script is designed to be safe to run multiple times, whether by a developer on their local machine or as part of an automated CI/CD pipeline.

At a high level, the script manages two Amazon S3 buckets. The first bucket stores static website assets such as HTML, CSS, and JavaScript files that make up the frontend of the application. The second bucket is used for uploads and temporary data generated by the application. Each bucket has different lifecycle, security, and access requirements, and the script enforces these differences explicitly.

## Script Safety and Execution Model

The script begins by enabling strict Bash execution rules using the following command:

```bash
set -euo pipefail
```

This configuration ensures that the script exits immediately if any command fails (`-e`), if an undefined variable is referenced (`u`), or if an error occurs inside a pipeline (`o pipefail`). These safeguards are especially important in cloud automation because partial failures can leave infrastructure in an inconsistent or insecure state. By failing fast, the script avoids silently continuing after an unexpected error.

Configuration values such as bucket names, AWS region, logging helpers, and wrapper functions are loaded from a shared configuration file:

```bash
source "$(dirname "$0")/00-config.sh"
```

Separating configuration from logic allows the same script to be reused across environments such as development, staging, and production, while also making the script easier to maintain and reason about.

## Non-Interactive (CI/CD) Execution with `FORCE_DELETE`

The script supports both interactive and non-interactive execution modes. This is controlled through the `FORCE_DELETE` environment variable:

```bash
FORCE_DELETE="${FORCE_DELETE:-false}"
```

When the script is run normally, destructive operations such as deleting objects from an existing bucket require explicit user confirmation. This protects against accidental data loss during manual execution. Note that user’s input is normalized to avoid issues with capitalization, and deletion only proceeds if the user explicitly confirms the action. If the user declines, the function exits without modifying the bucket.

When `FORCE_DELETE=true` is set, as shown below, all confirmation prompts are skipped and deletions proceed automatically.

```sh
FORCE_DELETE=true ./01-create-s3-buckets.sh
```

This mode is intended for CI/CD pipelines where human interaction is not possible and where the intent to recreate infrastructure is explicit.

Temporary JSON files used during execution are cleaned up automatically using a Bash trap:

```bash
trap 'rm -f upload-lifecycle-policy.json upload-cors-policy.json' EXIT
```

This guarantees that configuration artifacts are removed regardless of whether the script completes successfully or exits early due to an error.

## Bucket Discovery and Safe Handling

Before creating any S3 bucket, the script checks whether the bucket already exists using the AWS S3 API:

```bash
aws s3api head-bucket --bucket "$BUCKET_NAME"
```

This approach is preferred over listing bucket contents because it is faster, permission-safe, and does not depend on the bucket’s region. If a bucket exists, the script then checks whether it contains any objects. Rather than scanning the entire bucket, which could be expensive and slow, the script only checks for the presence of at least one object:

```bash
aws s3api list-objects-v2 --max-items 1
```

If objects are found, the script either prompts the user for confirmation or deletes them automatically, depending on whether `FORCE_DELETE` is enabled. This design ensures that existing data is never removed without explicit intent.

## Bucket Creation and Regional Consistency

When a required bucket does not exist, it is created explicitly in the configured AWS region:

```bash
aws s3 mb "s3://$BUCKET_NAME" --region "$REGION"
```

Specifying the region avoids ambiguity and ensures that all resources are created in a predictable location. This is particularly important for applications that rely on region-specific services or compliance requirements.

## Ownership Enforcement and Public Access Protection

After ensuring that a bucket exists, the script applies ownership controls that enforce the bucket owner as the owner of all objects stored within it:

```bash
aws s3api put-bucket-ownership-controls
```

This prevents permission issues caused by object-level ACLs and aligns with AWS’s modern security recommendations.

To further protect against accidental exposure, the script explicitly blocks all forms of public access:

```bash
aws s3api put-public-access-block
```

This prevents public ACLs and public bucket policies from being applied, even accidentally. Although Amazon S3 is private by default, explicitly blocking public access provides an additional layer of defense and is commonly required in security reviews and audits.

## Lifecycle Management for the Upload Bucket

The upload bucket is configured with a lifecycle policy that automatically deletes objects after one day. The policy also aborts incomplete multipart uploads that have been inactive for more than one day. A simplified representation of this configuration is shown below:

```json
{
  "Expiration": { "Days": 1 },
  "AbortIncompleteMultipartUpload": {
    "DaysAfterInitiation": 1
  }
}
```

This lifecycle management is critical for controlling storage costs and preventing the accumulation of temporary or abandoned data. It also ensures that the upload bucket remains lightweight and self-maintaining.

## Versioning for Data Safety

Versioning is enabled on the upload bucket using the following command:

```bash
aws s3api put-bucket-versioning --versioning-configuration Status=Enabled
```

With versioning enabled, every modification to an object creates a new version rather than overwriting the existing one. This provides a safety net against accidental deletions or overwrites and is particularly useful during development and data processing workflows.

## Cross-Origin Resource Sharing (CORS)

To support browser-based uploads and downloads, the script configures a permissive CORS policy on the upload bucket. The policy allows common HTTP methods and accepts requests from any origin. While this configuration is intentionally broad to support early development, it is designed to be tightened later once a CloudFront distribution or known frontend domain is in place.

## Completion and Handoff

At the end of execution, the script logs a summary confirming that both buckets have been successfully configured and indicates the next step in the deployment pipeline. This makes the script suitable for both human execution and automated pipelines, as it provides a clear signal that infrastructure provisioning has completed successfully.

The next stage of the project assumes that these buckets exist, are secure, and are correctly configured. Specifically, the deployment of the static website depends on the static bucket being present and locked down, while application workflows depend on the upload bucket’s lifecycle and versioning behavior.
